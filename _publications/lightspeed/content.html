<head>
  <link rel="stylesheet" href="overlay.css">
</head>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <p class="content has-text-justified">
          <img class="teaser-image" width="100%" src="./assets/teaser_header_crop.png" />
          <div class="columns is-multiline is-centered">
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/src_11_3_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/trg_11_3_gt_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/geosc/trg_11_3_crop_blend.gif" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/myr79hob/trg_11_3_crop_blend.gif" />
            </div>
          </div>
          <div class="columns is-multiline is-centered">
            <div class="column is-one-quarter has-text-centered">

              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/src_10_1_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/trg_10_1_gt_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/geosc/trg_10_1_crop_blend.gif" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/myr79hob/trg_10_1_crop_blend.gif" />
            </div>
          </div>
          <div class="columns is-multiline is-centered">
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/src_01_4_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/dinov2_518_upft1/trg_01_4_gt_crop.png" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/geosc/trg_01_4_crop_blend.gif" />
            </div>
            <div class="column is-one-quarter has-text-centered">
              <img class="overlay-gif" src="./assets/ap10kpairs/mouse/myr79hob/trg_01_4_crop_blend.gif" />
            </div>
          </div>
          </p>
          <p class="content has-text-justified">
            <i><b>Qualitative Results.</b> From left to right: source image with query keypoint, target image with
              ground truth correspondence, the baseline method, and our method. Our method is able to predict accurate
              correspondences in a fraction of the time compared to the baseline.</i>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in feature computation have revealed that self-supervised feature extractors can recognize semantic correspondences. However, these features often lack an understanding of objects' underlying geometry and 3D structure. In this paper, we focus on object categories with well-defined shapes and address the challenge of matching semantically similar parts distinguished by their geometric properties, e.g., left/right eyes or front/back legs. We propose a novel, optimal-transport based learning method that is faster and outperforms previous supervised methods in terms of semantic matching and geometric understanding.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-left">Overview</h2>
          <br><br>
          a) We develop a new method for image key points prediction based on optimal transport and <b><em>KL-regularized soft assignment</em></b>; it enables efficient and robust key point matching, showing a better understanding of geometrical features.
          <br>
          b) We demonstrate that our novel formulation provides state-of-the-art performance while being also lightfast; our method outperforms competitors on multiple datasets, and it takes <b><em>98% less time</em></b>.
          <br>
          c) We provide an extensive <b><em>analysis of the common PCK metric</em></b>, and we complement it; we proposea <b><em>new evaluation</em></b> that provide better insights into the geometrical understanding of the methods and also the accuracy of their similarity prediction.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-left">Method</h2>
          <p class="content has-text-justified">
            <img width="100%" src="./assets/architecture.png" />
            <br><br>
            <i><b>Training Scheme Overview.</b></i>
            <br>
          <p class="content has-text-justified">
            Given a dataset with keypoint annotation we can train the attention head by comparing the estimated assignment obtained from the KL-regularized Optimal Transport layer $ \widehat{P}^{\lambda,\alpha, \beta}$ to the sparse ground truth assignment giving us following loss function: $$ \mathcal{L} = - \sum_{(i,j)\in \mathcal{M}^+ \cup \mathcal{M}^0} \log \widehat{P}^{\lambda,\alpha, \beta}_{i,j} \, -\sum_{(i,j)\in \mathcal{M}^-} \log (1- \widehat{P}^{\lambda,\alpha, \beta}_{i,j}).$$
          </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<style>
  ol {
    list-style: none; /* Remove the default numbering */
  }
  ol > li {
    position: relative; /* Needed for positioning the marker */
    padding-left: 1.5em; /* Space between marker and text */
  }
  ol > li::before {
    content: "[" counter(list-item) "]"; /* Add brackets around the number */
    position: absolute; /* Position the custom marker */
    left: 0; /* Align the marker to the left */
  }
</style>
<!--Create a section with references with numbers in brackets.-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-left">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-left">Related Work</h2>
          <p class="content has-text-justified">
          <ol>
            <li>
              <a href="https://telling-left-from-right.github.io/">Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence</a>
            </li>
            <li>
              <a href="https://diffusionfeatures.github.io/">Emergent Correspondence from Image Diffusion</a>
            </li>
            <li>
              <a href="https://sd-complements-dino.github.io/">A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence</a>
            </li>
          </ol>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>